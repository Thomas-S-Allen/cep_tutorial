---
title: "Data Wrangling and Visualization"
author: "Thomas Allen"
date: "9/30/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(infer)
```



```{r}

within_radius_of_point <- function(df,point,radius) {
  
  # df : dataframe with RA and Dec columns (Decimal Degrees)
  
  # point : 2-element vector with center point RA and Dec (Decimal Degrees)
  
  # radius : radius to search within (Arcseconds)
  
  
df <-  df %>% 
  
  mutate(new_column_distance = sqrt( ((point[1] - RA) * 3600. * cos((pi/180.)*Dec))^2   +  ((Dec-point[2]) * 3600.)^2)) %>% 
  mutate(new_column = if_else(new_column_distance < radius,"yes", "no"))
  
df
  
}

```


```{r}

df <- read_csv("~/Websites/Working/thomas-s-allen 2/cep_tutorial/data/J.ApJ.750.125.ysos_2MASS_GAIA_raw.csv")

nrow(df)


#east_center <- c(344.2083, 62.6656)
east_center <- c(344.2060000, 62.6654278)
west_center <- c(343.4625, 62.5936)

radius <- 300.

df %>% distinct(Note)

parallax_conversion <- 10^3 # milli arcseconds to arcseconds

cols_to_keep <- c(
                  "RA",
                  "Dec",
                  "Type",
                  "Band1",
                  "Band2",
                  "Band3",
                  "Band4",
                  "Band5",
                  "Band6",
                  "Band7",
                  "Band8",
                  "Band9",
                  "Band10",
                  "Dust",
                  "Xray",
                  "parallax",
                  "parallax_error",
                  "pmra",
                  "pmra_error",
                  "pmdec",
                  "pmdec_error",
                  "teff_val",
                  "a_g_val",
                  "radius_val",
                  "lum_val"
                  )


df <- df %>%
  mutate(`V-I` = Vmag-`V-I`) %>% 
  mutate(Cl = fct_recode(Cl,"no disk"="III","disk"="II","disk"="TD","envelope"="I")) %>% 
  mutate(Note = case_when(Note=="x-ray" ~ "yes",
                            is.na(Note)==TRUE ~ "no")) %>% 
  rename(
    RA = `_RAJ2000`,
    Dec = `_DEJ2000`,
    Type = Cl,
    Band1 = Vmag,
    Band2 = `V-I`,
    Band3 = Jmag,
    Band4 = Hmag,
    Band5 = Ksmag,
    Band6 = `[3.6]`,
    Band7 = `[4.5]`,
    Band8 = `[5.8]`,
    Band9 = `[8.0]`,
    Band10 = `[24]`,
    Xray = Note,
    Dust = AKs
  ) %>% 
  select(cols_to_keep) %>% 
  #filter(Type %in% c("Disk","No Disk")) %>% 
  mutate(Distance = 1/ (parallax/parallax_conversion)) %>% 
  filter(Distance > 0,
         Distance < 10000) %>% 
  within_radius_of_point(east_center,radius) %>% 
  mutate(east_cluster = new_column) %>% 
  select(-new_column) %>% 
  within_radius_of_point(west_center,radius) %>% 
  mutate(west_cluster = new_column) %>% 
  select(-new_column) %>% 
  mutate(Region = if_else(east_cluster=="yes","east",if_else(west_cluster=="yes","west","halo"))) %>% 
  select(-new_column_distance,-east_cluster,-west_cluster)

df




#write_csv(df, file="/Desktop/exam_prep.csv")
```

## Problem 1

We are interested in exploring whether the presence (or lack thereof) of a protoplanetary disk around a young star depends on the location of that star in its birth cluster.  In this dataset, the `Region` variable gives the location of the stars in the cluster as "east", "west" and "halo". And the `Type` variable states disk presence as "disk", "no disk" and "envelope".  You can either include cases of `Type` "envelope" with the "disk" cases or ignore them.  For this problem:

  * Perform an exploratory data analysis, choosing an appropriate visualization and table.
  * Consider two cases, first, just the "east" and "west" categories in `Region` and second, all three categories in `Region`: "east, "west" and "halo".  By both choosing an appropriate probability model and using a computational method with `infer()`, for each case:
      + Calculate an appropriate point estimate and construct a $95\%$-confidence interval around your point estimate.  For the case of more than two categories, discuss the appropriatness of a confidence interval.
      + Formulate null and alternative hypotheses and construct a hypothesis test, calculate a p-value and draw a conclusion.
      + Discuss the relevent criteria for each approach and whether the data conform to the criteria.

**Note:** After using the `filter()` function, it may be useful to use `fct_drop()` to ensure any categories with a 0 count are dropped.

*****************************************************************************************

### Exploratory Data Analysis

First, we want to explore our data.  Create a useful table and visualization to show the relationship between `Type` and `Region`.


```{r}

df_counts <- df %>% 
 # filter(Xray=="yes",
 #       Type %in% c("Disk","No Disk")) %>% 
  filter(Type %in% c("disk","no disk")) %>% 
         #Subcluster %in% c("east","west")) %>% 
  group_by(Region,Type) %>% 
  summarize(counts=n()) %>% 
  mutate(freq=counts/sum(counts))

df_counts

df_counts %>% 
  ggplot(aes(x=Region,y=counts,fill=Type)) +
    geom_col(position="fill")

```


### Two Categories

#### Confidence intervals

Now just consider the regions "east" and "west".  For eash region estimate the proportion of stars with a protoplanetary disk and determine $95\%$ confidence intervals.

*****************************************************************************************

##### Approximation with probability models

The confidence interval around a single proportion point estimate is
$$
\begin{aligned}
\hat{p} & \pm MOE \\
\hat{p} & \pm z^{*} \times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
\end{aligned}
$$
For the "east" region, since there are 192 stars with a disk and 240 without, $\hat{p} = \frac{192}{192 + 240} = 0.44$:
$$
\begin{aligned}
\hat{p_{east}} & \pm z^{*} \times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \\
0.44 & \pm 1.96 \times \sqrt{\frac{0.44(1-0.44)}{432}} \\
0.44 & \pm 0.05
\end{aligned}
$$

```{r}

1.96 * sqrt( (0.44 * (1 - 0.44)) / 432)

```
And for the "west" region, since there are 159 stars with a disk and 134 without, $\hat{p} = \frac{159}{159 + 134} = 0.54$:
$$
\begin{aligned}
\hat{p_{west}} & \pm z^{*} \times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \\
0.54 & \pm 1.96 \times \sqrt{\frac{0.54(1-0.54)}{293}} \\
0.54 & \pm 0.06
\end{aligned}
$$

```{r}

1.96 * sqrt( (0.54 * (1 - 0.54)) / 293)

```
Therefore, we think that a plausable range of values that contain the popultation porportion in the east region is, $p_{east}$, is $0.39 - 0.49$, and for the west, $p_{west}$, is $0.48 - 0.6$.

##### Computational method with Infer

We will use `infer` to construct bootstrap estimations of the sampling distribution.  

```{r}

# First 

df_two <- df %>% 
  filter(Region %in% c("east","west"),
         Type %in% c("disk","no disk")) %>% 
  mutate(Region=factor(Region),
         Type=factor(Type))

df_two %>% 
  group_by(Region, Type) %>%
  summarise(count = n()) %>% 
  mutate(Type = fct_drop(Type))

# east
prop_east <- df_two %>% 
  filter(Region == "east") %>% 
  specify(response = Type, success = "disk") %>% 
  calculate(stat = "prop")

boot_east <- df_two %>% 
  filter(Region == "east") %>% 
  specify(response = Type, success = "disk") %>% 
  generate(reps=1000,type="bootstrap") %>% 
  calculate(stat = "prop") 

ci_east <- boot_east %>% 
  get_confidence_interval(type = "se", point_estimate = prop_east)

prop_east

ci_east

# west
prop_west <- df_two %>% 
  filter(Region == "west") %>% 
  specify(response = Type, success = "disk") %>% 
  calculate(stat = "prop")

boot_west <- df_two %>% 
  filter(Region == "west") %>% 
  specify(response = Type, success = "disk") %>% 
  generate(reps=1000,type="bootstrap") %>% 
  calculate(stat = "prop") 

ci_west <- boot_west %>% 
  get_confidence_interval(type = "se", point_estimate = prop_west)

prop_west

ci_west



# Construct Bootstrap Distributions

#boot_dist <- df_two %>% 
#  specify(response = Type, success = "disk") %>% 
#  generate(reps=1000, type="bootstrap") %>% 
#  calculate(stat = "prop")

```






*****************************************************************************************

##### Hypothesis testing

Now answer the question, "Do the proportions of stars with disks differ with region?"  Formulate a null and alterntive hypothesis, calculate a test statistic and a p-value and then make a conclusion about your hypotheis.


We will formulate our hypotheses as:
$$
\begin{aligned}
H_{0} &: p_{east} - p_{west} = 0 \\
H_{A} &: p_{east} - p_{west} \ne 0

\end{aligned}
$$

We can calculate a $z-score$ test statistic to test this hypothesis:
$$
\begin{aligned}
z & = \frac{\hat{p_{east}} - \hat{p_{west}} - 0}{\sqrt{\frac{\hat{p_{east}}(1-\hat{p_{east}})}{n_{east}} + 
    \frac{\hat{p_{west}}(1-\hat{p_{west}})}{n_{west}}}} \\
z & = \frac{0.44 - 0.54 - 0}{\sqrt{\frac{0.44(1-0.44)}{432} + 
    \frac{0.54(1-0.54)}{293}}} \\
z & = -2.66
\end{aligned}
$$

```{r}

z_score <- (0.44 - 0.54 - 0) / sqrt( (0.44*(1-0.44)/432) + (0.54*(1-0.54)/293))

z_score

```

Now that we have a z-score, we can calculate a p-value.  Our hypotheses call for a two-sided test, so:
```{r}

p_value = 2 * pnorm(q=-2.66, mean=0, sd=1)

p_value

```

##### Computational method with Infer

Using infer we will generate the null distribution using the permutation method.  Two appropriate test statistics are, 1) the difference in proportions, 2) a z-score.  First calculating a z-score.
```{r}
test_stat <- df_two %>% 
  specify(Type ~ Region, success = "disk") %>% 
  calculate(stat = "z", order = c("east","west"))

test_stat

null_dist <- df_two %>% 
  specify(Type ~ Region, success = "disk") %>% 
  hypothesise(null="independence") %>% 
  generate(reps=1000,type="permute") %>% 
  calculate(stat = "z", order = c("east","west"))

p_value <- null_dist %>% 
  get_p_value(obs_stat=test_stat, direction="two-sided")

p_value

null_dist %>% visualise(obs_stat = test_stat)
```
Now we will use the difference in proportions as the test statistic.
```{r}
test_stat <- df_two %>% 
  specify(Type ~ Region, success = "disk") %>% 
  calculate(stat = "diff in props", order = c("east","west"))

test_stat

null_dist <- df_two %>% 
  specify(Type ~ Region, success = "disk") %>% 
  hypothesise(null="independence") %>% 
  generate(reps=1000,type="permute") %>% 
  calculate(stat = "diff in props", order = c("east","west"))

p_value <- null_dist %>% 
  get_p_value(obs_stat=test_stat, direction="two-sided")

p_value

null_dist %>% visualise(obs_stat=test_stat)
```

This p-value is quite small, and is strong evidence to reject the null hypothesis.  Therefore, we conclude that the proportion of stars with disks differs between the "east" and "west" regions.

### More than two Categories


##### Confidence Intervals

Does it make sense to calculate a confidence interval when there is more than one category?


##### Hypothesis testing

We are still asking the question, "Is disk proportion related to Region".  Our null hypothesis is that disk proportion is independent of region and thus our alternative hypothesis is that disk proportion is dependent on region.  

We will formulate our hypotheses as:
$$
\begin{aligned}
H_{0} &: p_{east}  = p_{west} = p_{halo}  \\
H_{A} &: at~least~one~p~is~different
\end{aligned}
$$

###### Approximationb with Probability Models

We can use the $\Chi^{2}$ distribution to test this hypothesis.  First lets look at the two way table.



  counts      | east          | west          | halo          | total
------------- | ------------- | ------------- | ------------- | -------------
disk          | 192           | 159           | 507           | 858
no disk       | 240           | 134           | 929           | 1303
total         | 432           | 293           | 1436          | 2161


We can estimate the number of expected counts in any cell using the following:
$$

Expected_{i,j} = \frac{n_{row~i} \times n_{column~j} }{ table~total }

$$
Our table of expected counts is then

  counts      | east          | west          | halo          | total
------------- | ------------- | ------------- | ------------- | -------------
disk          | $\frac{858 \times 432}{2161}$ = 171.5 |  $\frac{858 \times 293}{2161}$ = 116.3  | $\frac{858 \times 1436}{2161}$ = 570.2| 858
no disk       | $\frac{1303 \times 432}{2161}$ = 260.5 |  $\frac{1303 \times 293}{2161}$ = 176.7 | $\frac{1303 \times 1436}{2161}$ = 865.9| 1303
total         | 432           | 293           | 1436          | 2161


To calculate the $\Chi^{2}$ test statistic, we first calculate a z-score for each cell.  
$$
\begin{aligned}
z & = \frac{observed~count - null~count}{Standard~Error} \\
z & = \frac{observed~count - null~count}{\sqrt{null~count}}
\end{aligned}
$$
Then each of these terms are squared and added together.

```{r}

chi_sq_stat <- ( (192 - 171.5)/sqrt(171.5) )^2 + 
          ( (159 - 116.3)/sqrt(116.3) )^2 + 
          ( (507 - 570.2)/sqrt(570.2) )^2 + 
          ( (240 - 260.5)/sqrt(260.5) )^2 + 
          ( (134 - 176.7)/sqrt(176.7) )^2 + 
          ( (929 - 865.9)/sqrt(865.9) )^2

chi_sq_stat
```
If $R$ is the number of categories in the response variable, and $C$ is the number of categories in the explanetory variable, then the degrees of freedom for a $\Chi^{2}$ test are given by:
$$
\begin{aligned}
df & = (R - 1) \times (C-1) \\
df & = (2 - 1) \times (3 -1) \\
df & = 1 \times 2 \\
df & = 2
\end{aligned}
$$

We can now calculate the p-value
```{r}

p_value <- 1 - pchisq(q=chi_sq_stat,df=2)

p_value

```

We can use the R function `chisq.test()` to perform a hypothesis test assuming the $\Chi^{2}$ probability model.

```{r}

df_three <- df %>% 
  filter(Type %in% c("disk","no disk")) %>% 
  select(Type,Region) %>% 
  mutate(Type = fct_drop(Type))

chisq.test(table(df_three$Type, df_three$Region))

```

##### Computational method with Infer

**Note:** `fct_drop()` is used here to remove the empty "envelope" category.


```{r}

df %>% 
  filter(Type %in% c("disk","no disk")) %>% 
  select(Type,Region) %>% 
  group_by(Region,Type) %>% 
  summarise(count=n())

df_three <- df %>% 
  filter(Type %in% c("disk","no disk")) %>% 
  select(Type,Region) %>% 
  mutate(Type = fct_drop(Type))

test_stat <- df_three %>% 
  specify(Type ~ Region) %>%
  #hypothesize(null = "independence") %>%
  #generate(reps = 1000, type = "permute") %>%
  calculate(stat = "Chisq")


test_stat

null_dist <- df_three %>% 
  specify(Type ~ Region) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "Chisq")

null_dist

p_value <- null_dist %>% 
  get_p_value(obs_stat = test_stat, direction="greater")

p_value

null_dist %>% visualise(obs_stat=test_stat)
```

As we see, regardless of method used, the test statistic is far into the wings of the null distribution.  Therefore, we consider that to be stron evidence to reject the null hypothesis that disk proportion and region are independent.  We conclude then, that disk proprtion depends on which region a star is in.


## Problem 2


We are now interested in exploring whether there are difference in the type of light emitted from each `Type` of star.  We will do this by creating a new *color index* composed of the measurements made in certain Bands.  To do this create a new variable called `Color` made of the difference `Band8`-`Band9`.  You will want to remove `NA`'s from this variable.

*****************************************************************************************

### Exploratory Data Analysis

```{r}

df_colors <- df %>% 
  mutate(Color = Band8 - Band9) %>% 
  #mutate(Color = Band1 - Band2) %>% 
  drop_na(Color)


# Boxplot of Index as function of Type (Disk or No Disk)
df_colors %>% 
  #drop_na(Band3,Band4,Band5,Band6,Band7,Band8,Band9) %>% 
  #mutate(Color1 = Band3-Band4,
  #       Color2 = Band6 - Band7, 
  #       Color3 = Band8 - Band9) %>% 
  ggplot(aes(x=Type, y=Color)) +
    geom_boxplot()


df_color_table <- df_colors %>% 
  group_by(Type) %>% 
  summarize(mean = mean(Color),sd=sd(Color),count=n())
  
df_color_table
```

### Two Categories

#### Confidence intervals

First, we just consider the regions "disk" and "no disk", and for eash type estimate the mean value of the color index and determine $95\%$ confidence intervals.

*****************************************************************************************

##### Approximation with probability models

For a single mean point estimate:
$$
\begin{aligned}
\bar{x} & \pm MOE \\
\bar{x} & \pm t_{df}^{*} \times \frac{s}{\sqrt{n}}
\end{aligned}
$$
The "disk" stars have a mean `Color` of `r df_color_table[df_color_table$Type == "disk","mean"]` with n = `r df_color_table[df_color_table$Type == "disk","count"]` observations, a sample standard deviation, s = `r df_color_table[df_color_table$Type == "disk","sd"]` and df = n-1 = `r df_color_table[df_color_table$Type == "disk","count"] - 1` degrees of freedom.  For a sample of this size $t_{df}^{*} \simeq z^{*}$.
$$
\begin{aligned}
\bar{x_{disk}} & \pm z^{*} \times \frac{s}{\sqrt{n}} \\
`r df_color_table[df_color_table$Type == "disk","mean"]` & \pm 1.96 \times \frac{`r df_color_table[df_color_table$Type == "disk","sd"]`}{\sqrt{`r df_color_table[df_color_table$Type == "disk","count"]`}} \\
`r df_color_table[df_color_table$Type == "disk","mean"]` & \pm 0.02 
\end{aligned}
$$

R can be used as a calculator.
```{r}

1.96 * df_color_table[df_color_table$Type == "disk","sd"] / sqrt(df_color_table[df_color_table$Type == "disk","count"])

#1.96 *  0.25 / sqrt(833) # If Color = Band8 - Band9

```


The "no disk" stars have a mean `Color` of `r df_color_table[df_color_table$Type == "no disk","mean"]` with n = `r df_color_table[df_color_table$Type == "no disk","count"]` observations, a sample standard deviation, s = `r df_color_table[df_color_table$Type == "no disk","sd"]` and df = n-1 = `r df_color_table[df_color_table$Type == "no disk","count"] - 1` degrees of freedom. Again, for a sample of this size $t_{df}^{*} \simeq z^{*}$.
$$
\begin{aligned}
\bar{x_{disk}} & \pm z^{*} \times \frac{s}{\sqrt{n}} \\
`r df_color_table[df_color_table$Type == "no disk","mean"]` & \pm 1.96 \times \frac{`r df_color_table[df_color_table$Type == "no disk","sd"]`}{\sqrt{`r df_color_table[df_color_table$Type == "no disk","count"]`}} \\
`r df_color_table[df_color_table$Type == "no disk","mean"]` & \pm 0.01
\end{aligned}
$$




```{r}

1.96 * df_color_table[df_color_table$Type == "no disk","sd"] / sqrt(df_color_table[df_color_table$Type == "no disk","count"])

1.96 *  0.23 / sqrt(1206)

```



##### Computational method with Infer

We will use `infer` to construct bootstrap estimations of the sampling distribution.  

```{r}

# First 
 
df_two <- df_colors %>% 
  filter(Type %in% c("disk","no disk")) %>% 
  mutate(Type = fct_drop(Type))

df_two

# disk
mean_disk <- df_two %>% 
  filter(Type == "disk") %>% 
  specify(response = Color) %>% 
  calculate(stat = "mean")

boot_disk <- df_two %>% 
  filter(Type == "disk") %>% 
  specify(response = Color) %>% 
  generate(reps=1000,type="bootstrap") %>% 
  calculate(stat = "mean") 

ci_disk <- boot_disk %>% 
  get_confidence_interval(type = "se", point_estimate = mean_disk)

mean_disk

ci_disk

# no disk
mean_nodisk <- df_two %>% 
  filter(Type == "no disk") %>% 
  specify(response = Color) %>% 
  calculate(stat = "mean")

boot_nodisk <- df_two %>% 
  filter(Type == "no disk") %>% 
  specify(response = Color) %>% 
  generate(reps=1000,type="bootstrap") %>% 
  calculate(stat = "mean") 

ci_nodisk <- boot_nodisk %>% 
  get_confidence_interval(type = "se", point_estimate = mean_nodisk)

mean_nodisk

ci_nodisk


```


##### Hypothesis testing

Now answer the question, "Does `Color` depend on `Type`?"  Formulate a null and alterntive hypothesis, calculate a test statistic and a p-value and then make a conclusion about your hypotheis.


We will formulate our hypotheses as:
$$
\begin{aligned}
H_{0} &: \mu_{disk} - \mu_{no~disk} = 0 \\
H_{A} &: \mu_{disk} - \mu_{no~disk} \ne 0

\end{aligned}
$$


##### Approximation with probability models

We will first approximate the null distribution using a t-distribution.  

$$
\begin{aligned}
t & = \frac{ \bar{x_{disk}}-\bar{x_{no~disk}} - 0 }{\sqrt{ \frac{s_{disk}^{2}}{n_{disk}} +
  \frac{s_{no~disk}^{2}}{n_{no~disk}}  }} \\
t & = \frac{ \bar{`r df_color_table[df_color_table$Type == "disk","mean"]`}-\bar{`r df_color_table[df_color_table$Type == "no disk","mean"]`} - 0 }{\sqrt{ \frac{`r df_color_table[df_color_table$Type == "no disk","sd"]`^{2}}{`r df_color_table[df_color_table$Type == "disk","count"]`} +
  \frac{`r df_color_table[df_color_table$Type == "no disk","sd"]`^{2}}{`r df_color_table[df_color_table$Type == "no disk","count"]`}  }} \\
0.03 & \pm 0.01
\end{aligned}
$$

Using R as a calculator:
```{r}

t_stat <- (df_color_table[df_color_table$Type == "disk","mean"] - df_color_table[df_color_table$Type == "no disk","mean"]) / sqrt ( (df_color_table[df_color_table$Type == "disk","sd"]^2)/df_color_table[df_color_table$Type == "disk","count"] + (df_color_table[df_color_table$Type == "no disk","sd"]^2)/df_color_table[df_color_table$Type == "no disk","count"] ) 

df <- min(df_color_table[df_color_table$Type == "no disk","count"],df_color_table[df_color_table$Type == "disk","count"]) - 1

#df
t_stat <- t_stat %>% pull()

t_stat

```

And `pt()` can be used to calculate th p-value:
```{r}

p_value <- 2*(1 - pt(q=t_stat,df))

p_value
```

Another approach is to use the R function `t.test()`.

```{r}

df_two <- df_colors %>% 
  filter(Type %in% c("disk","no disk")) %>% 
  mutate(Type = fct_drop(Type))

t.test(Color ~ Type,data=df_two)


```


##### Computational method with Infer

```{r}
test_stat <- df_two %>% 
  specify(Color ~ Type) %>% 
  calculate(stat = "t",order = c("disk", "no disk"))

test_stat

null_dist <- df_two %>% 
  specify(Color ~ Type) %>% 
  hypothesise(null="independence") %>% 
  generate(reps=1000,type="permute") %>% 
  calculate(stat = "t",order = c("disk", "no disk"))

p_value <- null_dist %>% 
  get_p_value(obs_stat=test_stat, direction="two-sided")

p_value
```


### More than two Categories

We now consider all three types: "envelope", "disk" and "no disk".

We will formulate our hypotheses as:
$$
\begin{aligned}
H_{0} &: \mu_{disk}  = \mu_{no~disk} = \mu_{envelope}  \\
H_{A} &: at~least~one~\mu~is~different
\end{aligned}
$$

###### Approximationb with Probability Models


##### Computational method with Infer

```{r}

f_stat <- df_colors %>% 
  specify(Color ~ Type) %>% 
  calculate(stat = "F")

f_stat


null_dist <- df_colors %>% 
  specify(Color ~ Type) %>% 
  hypothesise(null="independence") %>% 
  generate(reps=1000,type="permute") %>% 
  calculate(stat = "F")


p_value <- null_dist %>% 
  get_p_value(obs_stat=f_stat,direction="greater")

p_value

```

Check conditions
```{r}



```



